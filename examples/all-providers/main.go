// Package main demonstrates using llmx with all supported providers
package main

import (
	"context"
	"fmt"
	"os"

	"github.com/llmx-ai/llmx"
)

func main() {
	ctx := context.Background()
	prompt := "ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"

	fmt.Println("ğŸŒ LLMX - All Providers Demo")
	fmt.Println("================================\n")

	// 1. OpenAI
	if apiKey := os.Getenv("OPENAI_API_KEY"); apiKey != "" {
		testProvider(ctx, "OpenAI (GPT-4)", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				OpenAI(apiKey).
				Model("gpt-4-turbo").
				Build()
		}, prompt)
	}

	// 2. Anthropic
	if apiKey := os.Getenv("ANTHROPIC_API_KEY"); apiKey != "" {
		testProvider(ctx, "Anthropic (Claude)", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				Anthropic(apiKey).
				Model("claude-3-5-sonnet-20241022").
				Build()
		}, prompt)
	}

	// 3. Google
	if apiKey := os.Getenv("GOOGLE_API_KEY"); apiKey != "" {
		testProvider(ctx, "Google (Gemini)", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				Google(apiKey).
				Model("gemini-1.5-pro").
				Build()
		}, prompt)
	}

	// 4. Groq (è¶…å¿«æ¨ç†)
	if apiKey := os.Getenv("GROQ_API_KEY"); apiKey != "" {
		testProvider(ctx, "Groq (Llama 3.3 70B)", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				Groq(apiKey).
				Model("llama-3.3-70b-versatile").
				Build()
		}, prompt)
	}

	// 5. DeepSeek (æ€§ä»·æ¯”ä¹‹ç‹)
	if apiKey := os.Getenv("DEEPSEEK_API_KEY"); apiKey != "" {
		testProvider(ctx, "DeepSeek (é«˜æ€§ä»·æ¯”)", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				DeepSeek(apiKey).
				Model("deepseek-chat").
				Build()
		}, prompt)
	}

	// 6. Mistral AI
	if apiKey := os.Getenv("MISTRAL_API_KEY"); apiKey != "" {
		testProvider(ctx, "Mistral AI (Large)", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				Mistral(apiKey).
				Model("mistral-large-latest").
				Build()
		}, prompt)
	}

	// 7. æ™ºè°± AI (GLM)
	if apiKey := os.Getenv("ZHIPU_API_KEY"); apiKey != "" {
		testProvider(ctx, "æ™ºè°± AI (GLM-4 Plus)", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				Zhipu(apiKey).
				Model("glm-4-plus").
				Build()
		}, prompt)
	}

	// 8. é€šä¹‰åƒé—®
	if apiKey := os.Getenv("DASHSCOPE_API_KEY"); apiKey != "" {
		testProvider(ctx, "é€šä¹‰åƒé—® (Qwen Max)", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				Tongyi(apiKey).
				Model("qwen-max").
				Build()
		}, prompt)
	}

	// 9. Ollama (æœ¬åœ°è¿è¡Œ)
	testProvider(ctx, "Ollama (æœ¬åœ°)", func() (*llmx.Client, error) {
		return llmx.NewClientBuilder().
			Ollama("http://localhost:11434").
			Model("llama3.3").
			Build()
	}, prompt)

	// 10. Hugging Face
	if token := os.Getenv("HF_TOKEN"); token != "" {
		testProvider(ctx, "Hugging Face", func() (*llmx.Client, error) {
			return llmx.NewClientBuilder().
				HuggingFace(token).
				Model("meta-llama/Meta-Llama-3.1-70B-Instruct").
				Build()
		}, prompt)
	}

	fmt.Println("\nâœ… æµ‹è¯•å®Œæˆï¼")
	fmt.Println("\nğŸ’¡ æç¤º:")
	fmt.Println("- è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡æ¥æµ‹è¯•ä¸åŒçš„ Provider")
	fmt.Println("- Ollama éœ€è¦æœ¬åœ°è¿è¡Œ (ollama serve)")
	fmt.Println("- éƒ¨åˆ† Provider å¯èƒ½éœ€è¦é¢å¤–é…ç½®")
}

func testProvider(ctx context.Context, name string, clientFactory func() (*llmx.Client, error), prompt string) {
	fmt.Printf("ğŸ“Œ %s\n", name)

	client, err := clientFactory()
	if err != nil {
		fmt.Printf("   âŒ åˆ›å»ºå¤±è´¥: %v\n\n", err)
		return
	}
	defer client.Close()

	resp, err := client.SimpleChat(ctx, prompt)
	if err != nil {
		fmt.Printf("   âŒ è°ƒç”¨å¤±è´¥: %v\n\n", err)
		return
	}

	// æˆªæ–­å“åº”ä»¥ä¾¿æ˜¾ç¤º
	if len(resp) > 100 {
		resp = resp[:100] + "..."
	}

	fmt.Printf("   âœ… %s\n\n", resp)
}
